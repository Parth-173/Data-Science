{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608937b9",
   "metadata": {},
   "source": [
    "###                                                     Practical No. 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350ab03",
   "metadata": {},
   "source": [
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbf0d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "925d9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. It involves the analysis, understanding, and generation of human language, enabling machines to process and comprehend text in a meaningful way. NLP techniques are widely used in various applications such as sentiment analysis, machine translation, chatbots, and information retrieval. Preprocessing is an essential step in NLP, which involves tokenization, part-of-speech tagging, stop words removal, stemming, and lemmatization.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\"\"\"\n",
    "In Python tokenization basically refers to splitting up a larger body of text into smaller lines, words or even creating words for a non-English language.\n",
    "\"\"\"\n",
    "tokens = word_tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "\"\"\"\n",
    "POS Tagging Parts of speech Tagging is responsible for reading the text in a language and assigning some specific token (Parts of Speech) to each word.\n",
    "\"\"\"\n",
    "pos_tags = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa39a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words removal\n",
    "\"\"\"\n",
    "Stop words removal in Python is a common preprocessing step in Natural Language Processing (NLP) applications.\n",
    "Stop words are words that do not add much meaning to a sentence and are pre-defined and cannot be removed\n",
    "\"\"\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bcd8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86f4a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8363df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document:\n",
      " Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. It involves the analysis, understanding, and generation of human language, enabling machines to process and comprehend text in a meaningful way. NLP techniques are widely used in various applications such as sentiment analysis, machine translation, chatbots, and information retrieval. Preprocessing is an essential step in NLP, which involves tokenization, part-of-speech tagging, stop words removal, stemming, and lemmatization.\n",
      "\n",
      "Tokens:\n",
      " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'using', 'natural', 'language', '.', 'It', 'involves', 'the', 'analysis', ',', 'understanding', ',', 'and', 'generation', 'of', 'human', 'language', ',', 'enabling', 'machines', 'to', 'process', 'and', 'comprehend', 'text', 'in', 'a', 'meaningful', 'way', '.', 'NLP', 'techniques', 'are', 'widely', 'used', 'in', 'various', 'applications', 'such', 'as', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'chatbots', ',', 'and', 'information', 'retrieval', '.', 'Preprocessing', 'is', 'an', 'essential', 'step', 'in', 'NLP', ',', 'which', 'involves', 'tokenization', ',', 'part-of-speech', 'tagging', ',', 'stop', 'words', 'removal', ',', 'stemming', ',', 'and', 'lemmatization', '.']\n",
      "\n",
      "POS Tags:\n",
      " [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('that', 'WDT'), ('focuses', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('interaction', 'NN'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('humans', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('involves', 'VBZ'), ('the', 'DT'), ('analysis', 'NN'), (',', ','), ('understanding', 'NN'), (',', ','), ('and', 'CC'), ('generation', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('language', 'NN'), (',', ','), ('enabling', 'VBG'), ('machines', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('comprehend', 'VB'), ('text', 'NN'), ('in', 'IN'), ('a', 'DT'), ('meaningful', 'JJ'), ('way', 'NN'), ('.', '.'), ('NLP', 'NNP'), ('techniques', 'NNS'), ('are', 'VBP'), ('widely', 'RB'), ('used', 'VBN'), ('in', 'IN'), ('various', 'JJ'), ('applications', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('machine', 'NN'), ('translation', 'NN'), (',', ','), ('chatbots', 'NNS'), (',', ','), ('and', 'CC'), ('information', 'NN'), ('retrieval', 'NN'), ('.', '.'), ('Preprocessing', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('essential', 'JJ'), ('step', 'NN'), ('in', 'IN'), ('NLP', 'NNP'), (',', ','), ('which', 'WDT'), ('involves', 'VBZ'), ('tokenization', 'NN'), (',', ','), ('part-of-speech', 'JJ'), ('tagging', 'NN'), (',', ','), ('stop', 'VB'), ('words', 'NNS'), ('removal', 'JJ'), (',', ','), ('stemming', 'VBG'), (',', ','), ('and', 'CC'), ('lemmatization', 'NN'), ('.', '.')]\n",
      "\n",
      "Filtered Tokens (after stop words removal):\n",
      " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'artificial', 'intelligence', '(', 'AI', ')', 'focuses', 'interaction', 'computers', 'humans', 'using', 'natural', 'language', '.', 'involves', 'analysis', ',', 'understanding', ',', 'generation', 'human', 'language', ',', 'enabling', 'machines', 'process', 'comprehend', 'text', 'meaningful', 'way', '.', 'NLP', 'techniques', 'widely', 'used', 'various', 'applications', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'chatbots', ',', 'information', 'retrieval', '.', 'Preprocessing', 'essential', 'step', 'NLP', ',', 'involves', 'tokenization', ',', 'part-of-speech', 'tagging', ',', 'stop', 'words', 'removal', ',', 'stemming', ',', 'lemmatization', '.']\n",
      "\n",
      "Stemmed Tokens:\n",
      " ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'artifici', 'intellig', '(', 'ai', ')', 'focus', 'interact', 'comput', 'human', 'use', 'natur', 'languag', '.', 'involv', 'analysi', ',', 'understand', ',', 'gener', 'human', 'languag', ',', 'enabl', 'machin', 'process', 'comprehend', 'text', 'meaning', 'way', '.', 'nlp', 'techniqu', 'wide', 'use', 'variou', 'applic', 'sentiment', 'analysi', ',', 'machin', 'translat', ',', 'chatbot', ',', 'inform', 'retriev', '.', 'preprocess', 'essenti', 'step', 'nlp', ',', 'involv', 'token', ',', 'part-of-speech', 'tag', ',', 'stop', 'word', 'remov', ',', 'stem', ',', 'lemmat', '.']\n",
      "\n",
      "Lemmatized Tokens:\n",
      " ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'artificial', 'intelligence', '(', 'AI', ')', 'focus', 'interaction', 'computer', 'human', 'using', 'natural', 'language', '.', 'involves', 'analysis', ',', 'understanding', ',', 'generation', 'human', 'language', ',', 'enabling', 'machine', 'process', 'comprehend', 'text', 'meaningful', 'way', '.', 'NLP', 'technique', 'widely', 'used', 'various', 'application', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'chatbots', ',', 'information', 'retrieval', '.', 'Preprocessing', 'essential', 'step', 'NLP', ',', 'involves', 'tokenization', ',', 'part-of-speech', 'tagging', ',', 'stop', 'word', 'removal', ',', 'stemming', ',', 'lemmatization', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Document:\\n\", document)\n",
    "print(\"\\nTokens:\\n\", tokens)\n",
    "print(\"\\nPOS Tags:\\n\", pos_tags)\n",
    "print(\"\\nFiltered Tokens (after stop words removal):\\n\", filtered_tokens)\n",
    "print(\"\\nStemmed Tokens:\\n\", stemmed_tokens)\n",
    "print(\"\\nLemmatized Tokens:\\n\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a07462",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5475c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c40d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of documents\n",
    "documents = [\n",
    "    \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "    \"It focuses on the interaction between computers and humans using natural language.\",\n",
    "    \"NLP techniques are widely used in various applications such as sentiment analysis and machine translation.\",\n",
    "    \"Preprocessing is an essential step in NLP.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7be4f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33cf1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07d47b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fda893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "artificial: 0.3817\n",
      "intelligence: 0.3817\n",
      "is: 0.3009\n",
      "language: 0.3009\n",
      "natural: 0.3009\n",
      "of: 0.3817\n",
      "processing: 0.3817\n",
      "subfield: 0.3817\n",
      "\n",
      "Document 2:\n",
      "and: 0.2392\n",
      "between: 0.3034\n",
      "computers: 0.3034\n",
      "focuses: 0.3034\n",
      "humans: 0.3034\n",
      "interaction: 0.3034\n",
      "it: 0.3034\n",
      "language: 0.2392\n",
      "natural: 0.2392\n",
      "on: 0.3034\n",
      "the: 0.3034\n",
      "using: 0.3034\n",
      "\n",
      "Document 3:\n",
      "analysis: 0.2686\n",
      "and: 0.2117\n",
      "applications: 0.2686\n",
      "are: 0.2686\n",
      "as: 0.2686\n",
      "in: 0.2117\n",
      "machine: 0.2686\n",
      "nlp: 0.2117\n",
      "sentiment: 0.2686\n",
      "such: 0.2686\n",
      "techniques: 0.2686\n",
      "translation: 0.2686\n",
      "used: 0.2686\n",
      "various: 0.2686\n",
      "widely: 0.2686\n",
      "\n",
      "Document 4:\n",
      "an: 0.4129\n",
      "essential: 0.4129\n",
      "in: 0.3256\n",
      "is: 0.3256\n",
      "nlp: 0.3256\n",
      "preprocessing: 0.4129\n",
      "step: 0.4129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the TF-IDF representation\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    for j, term in enumerate(feature_names):\n",
    "        tfidf_value = tfidf_matrix[i, j]\n",
    "        if tfidf_value > 0:\n",
    "            print(f\"{term}: {tfidf_value:.4f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
